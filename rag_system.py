# rag_system.py - Syst√®me RAG pour Piscinik (VERSION PROPRE)
import os
import numpy as np
import pandas as pd
import faiss
from typing import List, Tuple
from openai import AsyncOpenAI
import asyncio
from pathlib import Path
import logging

logger = logging.getLogger(__name__)

class PiscinikRAG:
    def __init__(self, data_dir: str = "rag_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # Fichiers
        self.csv_path = self.data_dir / "piscinik_knowledge.csv"
        self.embeddings_path = self.data_dir / "embeddings.npy"
        self.index_path = self.data_dir / "faiss_index.bin"
        
        # OpenAI client
        self.client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.embedding_model = "text-embedding-3-small"
        self.embedding_dim = 1536  # Dimension pour text-embedding-3-small
        
        # FAISS index et donn√©es
        self.index = None
        self.chunks = []
        self.initialized = False
        
    async def initialize(self):
        """Initialise le syst√®me RAG (embeddings une seule fois)"""
        if self.initialized:
            return
            
        try:
            if self._files_exist():
                await self._load_existing()
            else:
                # Pour √©viter les timeouts, initialisation diff√©r√©e
                logger.warning("‚ö†Ô∏è Fichiers RAG non trouv√©s - cr√©ation diff√©r√©e √† la premi√®re utilisation")
                self.chunks = []
                self.initialized = True
                return
            
            self.initialized = True
            logger.info(f"‚úÖ RAG initialis√© avec {len(self.chunks)} chunks")
            
        except Exception as e:
            logger.error(f"‚ùå Erreur initialisation RAG: {e}")
            # Mode d√©grad√© - continuer sans RAG
            self.chunks = []
            self.initialized = True
    
    def _files_exist(self) -> bool:
        """V√©rifie si les fichiers d'index existent d√©j√†"""
        return (self.csv_path.exists() and 
                self.embeddings_path.exists() and 
                self.index_path.exists())
    
    async def _load_existing(self):
        """Charge l'index existant (rapide)"""
        logger.info("üìÇ Chargement de l'index RAG existant...")
        
        # Charger les chunks
        df = pd.read_csv(self.csv_path)
        self.chunks = df['content'].tolist()
        
        # Charger l'index FAISS
        self.index = faiss.read_index(str(self.index_path))
        
        logger.info(f"‚úÖ Index charg√© : {len(self.chunks)} chunks")
    
    async def _create_embeddings(self):
        """Cr√©e les embeddings (une seule fois)"""
        if not self.csv_path.exists():
            raise FileNotFoundError(f"CSV non trouv√© : {self.csv_path}")
        
        logger.info("üöÄ Cr√©ation des embeddings (premi√®re fois)...")
        
        # Lire le CSV
        df = pd.read_csv(self.csv_path)
        self.chunks = df['content'].tolist()
        
        # Cr√©er les embeddings par batch
        embeddings = []
        batch_size = 20  # Plus petit pour √©viter les rate limits
        
        for i in range(0, len(self.chunks), batch_size):
            batch = self.chunks[i:i + batch_size]
            
            try:
                response = await self.client.embeddings.create(
                    model=self.embedding_model,
                    input=batch
                )
                
                batch_embeddings = [data.embedding for data in response.data]
                embeddings.extend(batch_embeddings)
                
                logger.info(f"üìä Embeddings cr√©√©s : {len(embeddings)}/{len(self.chunks)}")
                
                # Pause pour respecter les rate limits
                if i + batch_size < len(self.chunks):
                    await asyncio.sleep(0.2)
                    
            except Exception as e:
                logger.error(f"Erreur cr√©ation embeddings batch {i}: {e}")
                raise
        
        # Cr√©er l'index FAISS
        embeddings_array = np.array(embeddings, dtype=np.float32)
        
        # Normaliser pour cosine similarity
        faiss.normalize_L2(embeddings_array)
        
        # Cr√©er l'index
        self.index = faiss.IndexFlatIP(self.embedding_dim)
        self.index.add(embeddings_array)
        
        # Sauvegarder
        np.save(self.embeddings_path, embeddings_array)
        faiss.write_index(self.index, str(self.index_path))
        
        logger.info("‚úÖ Embeddings cr√©√©s et sauvegard√©s")
    
    async def search(self, query: str, top_k: int = 3) -> List[Tuple[str, float]]:
        """Recherche les chunks les plus pertinents"""
        if not self.initialized:
            await self.initialize()
        
        # Si pas de chunks, cr√©er les embeddings maintenant
        if not self.chunks and self.csv_path.exists():
            logger.info("üöÄ Cr√©ation diff√©r√©e des embeddings...")
            await self._create_embeddings()
        
        if not self.chunks:
            logger.warning("‚ö†Ô∏è Aucun chunk disponible")
            return []
        
        try:
            logger.info(f"üîç Recherche RAG pour: '{query}'")
            
            # Cr√©er l'embedding de la query
            response = await self.client.embeddings.create(
                model=self.embedding_model,
                input=[query]
            )
            
            query_embedding = np.array([response.data[0].embedding], dtype=np.float32)
            faiss.normalize_L2(query_embedding)
            
            # Rechercher
            scores, indices = self.index.search(query_embedding, top_k)
            
            # Retourner les r√©sultats
            results = []
            for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
                if 0 <= idx < len(self.chunks):
                    chunk = self.chunks[idx]
                    results.append((chunk, float(score)))
                    logger.info(f"üìÑ R√©sultat {i+1} (score: {score:.3f}): {chunk[:100]}...")
            
            logger.info(f"‚úÖ {len(results)} chunks trouv√©s pour la recherche")
            return results
            
        except Exception as e:
            logger.error(f"‚ùå Erreur recherche RAG: {e}")
            return []
    
    async def get_answer(self, query: str) -> str:
        """G√©n√®re une r√©ponse bas√©e sur la recherche RAG"""
        try:
            logger.info(f"ü§ñ G√©n√©ration r√©ponse pour: '{query}'")
            
            # Rechercher les chunks pertinents
            relevant_chunks = await self.search(query, top_k=3)
            
            if not relevant_chunks:
                logger.warning("‚ö†Ô∏è Aucun chunk trouv√©")
                return "Je n'ai pas trouv√© d'information sp√©cifique sur ce sujet dans ma base de connaissances."
            
            # Construire le contexte
            context_parts = []
            for chunk, score in relevant_chunks:
                if score > 0.5:  # Seuil baiss√© de 0.7 √† 0.5 pour plus de r√©sultats
                    context_parts.append(chunk)
                    logger.info(f"‚úÖ Chunk retenu (score: {score:.3f})")
                else:
                    logger.info(f"‚ùå Chunk rejet√© (score: {score:.3f}) - seuil trop bas")
            
            if not context_parts:
                logger.warning("‚ö†Ô∏è Aucun chunk au-dessus du seuil 0.5")
                # Prendre au moins le meilleur r√©sultat
                context_parts = [relevant_chunks[0][0]]
                logger.info(f"üîÑ Utilisation du meilleur r√©sultat (score: {relevant_chunks[0][1]:.3f})")
            
            context = "\n\n".join(context_parts)
            logger.info(f"üìù Contexte construit avec {len(context_parts)} chunks")
            
            # G√©n√©rer la r√©ponse
            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": """Tu es l'expert technique de Piscinik. R√©ponds aux questions en te basant 
                        STRICTEMENT sur le contexte fourni. Sois CONCIS, pr√©cis et pratique. 
                        Donne 2-3 conseils concrets maximum, sans d√©tails inutiles. √âvite les longs paragraphes.
                        Si l'information n'est pas dans le contexte, dis-le bri√®vement."""
                    },
                    {
                        "role": "user", 
                        "content": f"Contexte technique :\n{context}\n\nQuestion client : {query}\n\nR√©ponse courte et pratique :"
                    }
                ],
                temperature=0.3,  # Plus d√©terministe pour les r√©ponses techniques
                max_tokens=150  # R√©duit de 300 √† 150 tokens pour des r√©ponses plus courtes
            )
            
            final_answer = response.choices[0].message.content
            logger.info(f"üéØ R√©ponse g√©n√©r√©e: {final_answer}")
            
            return final_answer
            
        except Exception as e:
            logger.error(f"‚ùå Erreur g√©n√©ration r√©ponse RAG: {e}")
            return "Je rencontre un probl√®me technique pour acc√©der √† ma base de connaissances. Pouvez-vous reformuler votre question ?"


# Instance globale pour r√©utilisation
_rag_instance = None

async def get_rag_system() -> PiscinikRAG:
    """Retourne l'instance RAG (singleton)"""
    global _rag_instance
    if _rag_instance is None:
        _rag_instance = PiscinikRAG()
        await _rag_instance.initialize()
    return _rag_instance


# Test du syst√®me
async def test_rag():
    """Test du syst√®me RAG"""
    rag = await get_rag_system()
    
    questions = [
        "Ma piscine est verte, que faire ?",
        "Comment √©quilibrer le pH ?",
        "Quelle est la dur√©e de filtration id√©ale ?",
        "Ma pompe ne s'amorce pas",
    ]
    
    for question in questions:
        print(f"\n‚ùì Question: {question}")
        answer = await rag.get_answer(question)
        print(f"üîß R√©ponse: {answer}")

if __name__ == "__main__":
    asyncio.run(test_rag())